{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matthew Zlibut**\n",
    "\n",
    "DATA set description\n",
    "\n",
    "Autism spectrum disorder (ASD) is a developmental disorder that affects communication and behavior. Unfortunately, waiting for an ASD diagnosis is lengthy and procedures are expensive. The economic impact of autism and the increase in the number of ASD cases across the world reveals an urgent need for the development of easily implemented and effective ASD screening methods.\n",
    "\n",
    "Column variables presented in this data: **AGE, GENDER, ETHNICITY, JAUNDICE, FAMILY with PDD, TEST TAKER, COUNTRY, etc.**\n",
    "\n",
    "The **age** of the patient was a number presented in years old. \n",
    "\n",
    "**Gender** was only measured to be M or F, which is translated to a 1 or 0 in our data.\n",
    "\n",
    "**Ethnicity** was a string which lists ethnicities in text format. \n",
    "\n",
    "Born with **jaundice** is a Boolean value (True or False)\n",
    "\n",
    "**Family member with PDD** is a Boolean value (True or False)\n",
    "\n",
    "**Who is completing the test** is a String value. ex: Parent, self, caregiver, medical staff, clinician ,etc.\n",
    "\n",
    "**Country of residence** is a String, List countries in text format\n",
    "\n",
    "**Used the screening app before** Boolean (yes or no) Whether the user has used a screening app\n",
    "\n",
    "Question 1-10 Answer Binary (0, 1) The answer code of the question based on the screening\n",
    "\n",
    "method used\n",
    "\n",
    "Screening Score Integer The final score obtained based on the scoring algorithm of the\n",
    "screening method used. This was computed in an automated manner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>...</th>\n",
       "      <th>ethnicity_Asian</th>\n",
       "      <th>ethnicity_Black</th>\n",
       "      <th>ethnicity_Hispanic</th>\n",
       "      <th>ethnicity_Latino</th>\n",
       "      <th>ethnicity_Pasifika</th>\n",
       "      <th>ethnicity_Turkish</th>\n",
       "      <th>ethnicity_White-European</th>\n",
       "      <th>relation_'Health care professional'</th>\n",
       "      <th>relation_Relative</th>\n",
       "      <th>relation_Self</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  \\\n",
       "287         1         1         1         1         1         1         1   \n",
       "288         1         0         0         0         1         0         1   \n",
       "289         1         0         1         1         1         1         1   \n",
       "290         1         1         1         0         1         1         1   \n",
       "291         0         0         1         0         1         0         1   \n",
       "\n",
       "     A8_Score  A9_Score  A10_Score      ...        ethnicity_Asian  \\\n",
       "287         1         1          1      ...                      0   \n",
       "288         0         0          1      ...                      0   \n",
       "289         0         0          1      ...                      0   \n",
       "290         1         1          1      ...                      0   \n",
       "291         0         0          0      ...                      0   \n",
       "\n",
       "     ethnicity_Black  ethnicity_Hispanic  ethnicity_Latino  \\\n",
       "287                0                   0                 0   \n",
       "288                0                   0                 0   \n",
       "289                0                   0                 1   \n",
       "290                0                   0                 0   \n",
       "291                0                   0                 0   \n",
       "\n",
       "     ethnicity_Pasifika  ethnicity_Turkish  ethnicity_White-European  \\\n",
       "287                   0                  0                         1   \n",
       "288                   0                  0                         1   \n",
       "289                   0                  0                         0   \n",
       "290                   0                  0                         0   \n",
       "291                   0                  0                         0   \n",
       "\n",
       "     relation_'Health care professional'  relation_Relative  relation_Self  \n",
       "287                                    0                  0              0  \n",
       "288                                    0                  0              0  \n",
       "289                                    0                  0              0  \n",
       "290                                    0                  0              0  \n",
       "291                                    0                  0              0  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "\n",
    "def cross_validation(estimator, param_grid, X_train, y_train):\n",
    "    #returns a grid search object and cross-validatied scores in that order\n",
    "    gs = GridSearchCV(estimator=estimator,\n",
    "                 param_grid = param_grid,\n",
    "                 scoring='accuracy',\n",
    "                 cv=5, iid=False, refit=True,\n",
    "                n_jobs=-1)\n",
    "    scores = cross_validate(estimator=gs, X=X_train, y=y_train, cv=10, scoring='accuracy', return_train_score=True)\n",
    "    return gs, scores\n",
    "\n",
    "def print_scoring_metrics(method, y_true, y_pred, estimator, normalize=False):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(('%s score'+4*'%s %2.2f\\t')%(method, 'Accuracy', acc, 'Recall', rec, 'Precision', prec, 'F1', f1))\n",
    "    \n",
    "\n",
    "df = pd.read_csv('Autism-Child-Data.csv', na_values = '?')\n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "df = pd.get_dummies(df, columns=['country_of_res'], prefix = 'country')\n",
    "df = pd.get_dummies(df, columns=['ethnicity'])\n",
    "df = pd.get_dummies(df, columns=['relation'])\n",
    "\n",
    "df['relation_Self'] += df['relation_self']\n",
    "df = df.drop(axis=1, columns=['country_Italy',\n",
    "                              'ethnicity_Others',\n",
    "                             'relation_Parent',\n",
    "                             'relation_self',\n",
    "                             'age_desc',\n",
    "                             'result'])\n",
    "df['gender'] = df['gender'].map({'m': 0, 'f': 1})\n",
    "\n",
    "yn_mapping = {'yes':1,'YES':1,'no':0, 'NO':0}\n",
    "for label in ['jaundice', 'autism', 'class', 'used_app_before']:\n",
    "    df[label] = df[label].map(yn_mapping)\n",
    "    \n",
    "df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9552130325814536\n",
      "{'C': 100.0, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 2, 'gamma': 0.002154434690031882, 'kernel': 'sigmoid', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "Optimized SVC scoreAccuracy 0.88\tRecall 0.84\tPrecision 0.91\tF1 0.87\t\n"
     ]
    }
   ],
   "source": [
    "#SVC Data\n",
    "clf = SVC(gamma='auto')\n",
    "X = df.drop(axis=1, columns='class').values\n",
    "y = df['class'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "clf.fit(X_train_std, y_train) \n",
    "clf.predict(X_test_std)\n",
    "clf.score(X_test_std, y_test, sample_weight=None)\n",
    "\n",
    "C_range = np.logspace(-2, 4, 10)\n",
    "gamma_range = np.logspace(-4, 2, 10)\n",
    "\n",
    "param_grid = [{'C': C_range, 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': gamma_range, 'degree':[2,3,4]}]\n",
    "\n",
    "gs, scores = cross_validation(clf, param_grid, X_train_std, y_train)\n",
    "gs.fit(X_train_std, y_train)\n",
    "\n",
    "print(scores['test_score'].mean())\n",
    "\n",
    "best_SVC = gs.best_estimator_\n",
    "print(best_SVC.get_params())\n",
    "print_scoring_metrics('Optimized SVC', y_test, best_SVC.predict(X_test_std), best_SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9747368421052632\n"
     ]
    }
   ],
   "source": [
    "#LR\n",
    "lr = LogisticRegression(C=0.1, solver='lbfgs', multi_class='auto')\n",
    "lr.fit(X_train_std, y_train)\n",
    "lr.predict(X_test_std)\n",
    "lr.score(X_test_std, y_test)\n",
    "\n",
    "C_range = np.logspace(-2, 4, 10)\n",
    "l1_range = np.linspace(0.1, 1, 10)\n",
    "\n",
    "param_grid = [{'C': C_range, 'penalty': ['l2'], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']},\n",
    "             ]#{'C': C_range, 'penalty': ['elasticnet'], 'l1_ratio': l1_range, 'solver': ['saga']}]\n",
    "\n",
    "gs, scores = cross_validation(lr, param_grid, X_train_std, y_train)\n",
    "gs.fit(X_train_std, y_train)\n",
    "\n",
    "print(scores['test_score'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.046415888336127774, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Optimized lr scoreAccuracy 0.90\tRecall 0.92\tPrecision 0.88\tF1 0.90\t\n"
     ]
    }
   ],
   "source": [
    "best_lr = gs.best_estimator_\n",
    "print(best_lr.get_params())\n",
    "print_scoring_metrics('Optimized lr', y_test, best_lr.predict(X_test_std), best_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP\n",
    "mlp = MLPClassifier(solver='lbfgs')\n",
    "mlp.fit(X_train_std, y_train)\n",
    "mlp.predict(X_test_std)\n",
    "mlp.score(X_test_std, y_test)\n",
    "\n",
    "C_range = np.logspace(-2, 4, 10)\n",
    "l1_range = np.linspace(0.1, 1, 10)\n",
    "\n",
    "param_grid = [{'learning_rate': ['constant', 'invscaling', 'adaptive'], 'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "               'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
    "               'hidden_layer_sizes': [(73,), (73,37), (73,73,37)]}]\n",
    "\n",
    "gs, scores = cross_validation(mlp, param_grid, X_train_std, y_train)\n",
    "gs.fit(X_train_std, y_train)\n",
    "\n",
    "print(scores)\n",
    "               \n",
    "best_mlp = gs.best_estimator_\n",
    "print(best_mlp.get_params())\n",
    "print_scoring_metrics('Optimized MLP', y_test, best_mlp_predict(X_test_std), best_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
